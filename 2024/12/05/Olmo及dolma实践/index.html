<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Olmo及dolma实践 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="零、导言0.0 模型训练的总体流程模型训练的完整流程通常包括以下几个步骤：  数据准备：将原始数据通过数据清洗与处理，转化为可用于模型训练的高质量训练数据。Dolma 工具在此阶段发挥重要作用，确保数据经过标记、去重、过滤等处理步骤，形成高质量的训练语料。 词元切分：对训练数据进行 Tokenization，将文本数据转换为模型能够理解和处理的 tokens，生成可供训练的输入数据。 预训练：使用">
<meta property="og:type" content="article">
<meta property="og:title" content="Olmo及dolma实践">
<meta property="og:url" content="http://example.com/2024/12/05/Olmo%E5%8F%8Adolma%E5%AE%9E%E8%B7%B5/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="零、导言0.0 模型训练的总体流程模型训练的完整流程通常包括以下几个步骤：  数据准备：将原始数据通过数据清洗与处理，转化为可用于模型训练的高质量训练数据。Dolma 工具在此阶段发挥重要作用，确保数据经过标记、去重、过滤等处理步骤，形成高质量的训练语料。 词元切分：对训练数据进行 Tokenization，将文本数据转换为模型能够理解和处理的 tokens，生成可供训练的输入数据。 预训练：使用">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2024-12-05T15:13:57.000Z">
<meta property="article:modified_time" content="2024-12-05T15:15:08.851Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-Olmo及dolma实践" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/12/05/Olmo%E5%8F%8Adolma%E5%AE%9E%E8%B7%B5/" class="article-date">
  <time class="dt-published" datetime="2024-12-05T15:13:57.000Z" itemprop="datePublished">2024-12-05</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Olmo及dolma实践
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h3 id="零、导言"><a href="#零、导言" class="headerlink" title="零、导言"></a>零、导言</h3><h4 id="0-0-模型训练的总体流程"><a href="#0-0-模型训练的总体流程" class="headerlink" title="0.0 模型训练的总体流程"></a><strong>0.0 模型训练的总体流程</strong></h4><p>模型训练的完整流程通常包括以下几个步骤：</p>
<ol>
<li><strong>数据准备</strong>：将原始数据通过数据清洗与处理，转化为可用于模型训练的高质量训练数据。Dolma 工具在此阶段发挥重要作用，确保数据经过标记、去重、过滤等处理步骤，形成高质量的训练语料。</li>
<li><strong>词元切分</strong>：对训练数据进行 Tokenization，将文本数据转换为模型能够理解和处理的 tokens，生成可供训练的输入数据。</li>
<li><strong>预训练</strong>：使用训练数据对 OLMo 模型进行预训练，模型在大量数据上学习语言的基本规律和特征。</li>
<li><strong>指令微调</strong>：对预训练后的模型进行指令微调，使其能够更好地理解和执行特定任务指令。</li>
<li><strong>模型评测</strong>：使用 OpenCompass 工具对模型进行全面评测，包括对模型的语言理解、生成能力等多方面的评价，以便了解模型性能并进行进一步优化。</li>
</ol>
<h3 id="一、Docker使用与环境搭建"><a href="#一、Docker使用与环境搭建" class="headerlink" title="一、Docker使用与环境搭建"></a><strong>一、Docker使用与环境搭建</strong></h3><h4 id="1-1-Docker简介"><a href="#1-1-Docker简介" class="headerlink" title="1.1 Docker简介"></a><strong>1.1 Docker简介</strong></h4><p><strong>容器技术的定义</strong>：容器技术通过在物理主机操作系统上创建一个个孤立的分组（即容器），将应用程序及其依赖项打包在一个独立的容器中，使其能够在任何支持容器的环境中运行，而不受底层系统的影响。Docker 是目前主流的容器技术之一，其他类似的容器技术还有 Kubernetes (K8s) 等。</p>
<p><strong>Docker的特点</strong>：</p>
<ul>
<li><strong>轻量级</strong>：容器共享主机的操作系统内核，避免了虚拟机的资源开销，启动更快，占用更少资源。</li>
<li><strong>可移植性</strong>：容器技术允许应用程序在不同的云平台和数据中心中轻松迁移，确保在不同环境中运行时不会出现兼容性问题。</li>
<li><strong>一致性</strong>：容器保证了应用程序在不同环境中的一致性运行，减少了“在我的机器上能够运行”的问题，使得开发、测试、生产等环境的统一性得以保证。</li>
</ul>
<h4 id="1-2-Docker的基本概念"><a href="#1-2-Docker的基本概念" class="headerlink" title="1.2 Docker的基本概念"></a><strong>1.2 Docker的基本概念</strong></h4><p>Docker 包括三个基本概念：</p>
<ol>
<li><strong>镜像（Image）</strong>：Docker 镜像相当于一个 root 文件系统。例如，官方镜像 <code>ubuntu:16.04</code> 就包含了完整的一套 Ubuntu16.04 最小系统的 root 文件系统。镜像是静态的，作为容器的模板存在。</li>
<li><strong>容器（Container）</strong>：容器是镜像的运行实例，类似于面向对象编程中的类和对象。镜像是静态的定义，容器是镜像在运行时的实体。容器可以被创建、启动、停止、删除、暂停等。</li>
<li><strong>仓库（Repository）</strong>：仓库是用于保存镜像的地方，类似于代码控制中心。在仓库中，可以存储、获取、分发 Docker 镜像。</li>
</ol>
<h4 id="1-3-Docker安装与使用"><a href="#1-3-Docker安装与使用" class="headerlink" title="1.3 Docker安装与使用"></a><strong>1.3 Docker安装与使用</strong></h4><p><strong>安装Docker</strong>：请参考官方网站的安装指南，或者访问 <a target="_blank" rel="noopener" href="https://www.runoob.com/docker/ubuntu-docker-install.html">菜鸟教程Docker安装</a> 完成 Docker 的安装。</p>
<p><strong>常用操作命令</strong>：</p>
<ol>
<li><p><strong>下载镜像</strong>：通过命令 <code>docker pull &lt;镜像名&gt;</code> 下载所需的 Docker 镜像。例如，<code>docker pull ubuntu:16.04</code>。</p>
</li>
<li><p><strong>查看镜像</strong>：使用 <code>docker images</code> 查看已经下载到本地的镜像列表。</p>
</li>
<li><p><strong>启动容器</strong>：使用 <code>docker run [OPTIONS] &lt;image&gt; [COMMAND] [ARG...]</code> 从镜像启动一个新的容器。</p>
<ul>
<li>常用的 <code>OPTIONS</code> 参数：<ul>
<li><code>--gpus</code>：配置容器内部使用的 GPU，示例如 <code>--gpus all</code>。</li>
<li><code>-v &lt;host目录&gt;:&lt;容器目录&gt;</code>：挂载主机目录到容器中，例如挂载数据集等。在容器内部修改挂载的目录或文件会直接反映到宿主机。</li>
<li><code>--privileged</code>：使用该参数，容器内的 root 用户拥有真正的 root 权限。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="1-4-容器内部环境的安装与配置"><a href="#1-4-容器内部环境的安装与配置" class="headerlink" title="1.4 容器内部环境的安装与配置"></a><strong>1.4 容器内部环境的安装与配置</strong></h4><p>在启动并进入容器后，可以对容器内部进行各种环境的配置，例如安装 Anaconda 和其他必要的工具。</p>
<p><strong>步骤</strong>：</p>
<ol>
<li><strong>安装Anaconda</strong>：下载 Anaconda 安装文件，然后运行 <code>bash Anaconda****.sh</code> 进行安装。</li>
<li><strong>创建 Python 环境</strong>：使用 Anaconda 创建一个指定 Python 版本的环境，例如 <code>conda create –name myenv python=3.8</code>，然后使用 <code>conda activate myenv</code> 激活环境。</li>
<li><strong>安装Dolma</strong>：在已激活的 Anaconda 环境中，运行 <code>pip install dolma</code> 安装 Dolma 工具包。</li>
<li><strong>安装OLMo</strong>：参照 OLMo 的 GitHub 指导文档进行安装，并确保所使用的 PyTorch 版本与 CUDA 版本匹配，以获得最佳性能。</li>
</ol>
<p><strong>环境安装验证</strong>：完成所有安装后，可运行相关命令（例如 <code>python</code>、<code>pip list</code> 等）检查环境配置是否正确。</p>
<h4 id="1-5-容器的管理与镜像保存"><a href="#1-5-容器的管理与镜像保存" class="headerlink" title="1.5 容器的管理与镜像保存"></a><strong>1.5 容器的管理与镜像保存</strong></h4><p><strong>将容器放到后台运行</strong>：</p>
<ul>
<li>使用快捷键 <code>Ctrl + P + Q</code> 将当前容器放到后台运行，而不停止容器的执行。</li>
</ul>
<p><strong>查看正在运行的容器</strong>：</p>
<ul>
<li>通过 <code>docker ps</code> 查看当前运行的容器。如果容器已停止，可使用 <code>docker ps -a</code> 查看所有容器。</li>
</ul>
<p><strong>重新启动和进入容器</strong>：</p>
<ul>
<li>使用 <code>docker start &lt;容器ID&gt;</code> 启动已停止的容器。</li>
<li>使用 <code>docker attach &lt;容器ID&gt;</code> 进入正在运行的容器。</li>
</ul>
<p><strong>保存容器为镜像</strong>：</p>
<ul>
<li>通过 <code>docker commit &lt;容器ID&gt; &lt;镜像名&gt;</code> 将已配置好环境的容器保存为一个新的镜像。</li>
</ul>
<p><strong>保存镜像为离线文件</strong>：</p>
<ul>
<li>使用 <code>docker save -o &lt;文件名&gt;.tar &lt;镜像名&gt;:&lt;tag&gt;</code> 将镜像保存为 <code>.tar</code> 文件，便于在其他设备上使用。</li>
</ul>
<p><strong>加载离线镜像</strong>：</p>
<ul>
<li>使用 <code>docker load -i &lt;文件名&gt;.tar</code> 载入离线镜像，方便在新的环境中快速搭建所需环境。</li>
</ul>
<h3 id="二、数据收集与清洗"><a href="#二、数据收集与清洗" class="headerlink" title="二、数据收集与清洗"></a><strong>二、数据收集与清洗</strong></h3><h4 id="2-1-数据准备"><a href="#2-1-数据准备" class="headerlink" title="2.1 数据准备"></a><strong>2.1 数据准备</strong></h4><ul>
<li><strong>原料</strong>：原始文本数据是进行数据清洗与处理的基础，来源包括各种大型语料库和数据集。</li>
<li><strong>工具</strong>：Dolma 是一个高性能的数据清洗工具包，提供了完整的数据处理与清洗流程。</li>
<li><strong>步骤</strong>：<ol>
<li><strong>收集数据</strong>：从不同来源收集原始数据，例如 Common Crawl、The Stack、Wikipedia、Wikibooks 等。</li>
<li><strong>数据处理与清洗</strong>：使用 Dolma 工具对数据进行标记、去重、筛选与混合等处理。</li>
<li><strong>词元切分</strong>：将清洗后的文本进行分词，生成可供模型训练的 tokens。</li>
</ol>
</li>
<li><strong>结果</strong>：完成数据清洗与处理后，最终获得可供模型训练使用的 tokens，规模约在 100B 左右。</li>
</ul>
<h4 id="2-2-Dolma的特点"><a href="#2-2-Dolma的特点" class="headerlink" title="2.2 Dolma的特点"></a><strong>2.2 Dolma的特点</strong></h4><p>Dolma 是一款强大且灵活的数据处理工具包，具备以下主要特点：</p>
<ul>
<li><strong>高性能</strong>：能够并行处理包含数十亿个文档的数据集，支持高效的数据清洗与预处理。</li>
<li><strong>可移植性</strong>：Dolma 可在单机、集群或云计算环境中运行，灵活性强。</li>
<li><strong>内置标记器</strong>：内置多种标记器，包括语言检测、毒性检测、困惑度评分等，提供对文本的多维度分析和过滤。</li>
<li><strong>快速重复数据删除</strong>：采用 Rust 实现的 Bloom 过滤器，能够高效去除数据集中的重复文档，比其他方法快得多。</li>
<li><strong>可扩展</strong>：Dolma 设计为可扩展，可以根据需要使用自定义标记器。</li>
<li><strong>云支持</strong>：Dolma 支持从本地磁盘和 AWS S3 兼容位置读取和写入数据，便于云端与本地数据的交互。</li>
</ul>
<h4 id="2-3-Dolma数据处理流程"><a href="#2-3-Dolma数据处理流程" class="headerlink" title="2.3 Dolma数据处理流程"></a><strong>2.3 Dolma数据处理流程</strong></h4><p>使用 Dolma 进行数据集管理通常分为四个步骤：</p>
<ol>
<li><strong>标记数据</strong>：使用内置标记器对数据集中的文档进行标记，例如标记文档的语言、毒性等属性。</li>
<li><strong>重复数据删除</strong>：根据文档内容或元数据对文档进行去重。</li>
<li><strong>混合数据</strong>：根据文档的属性值，删除或过滤不符合要求的文档，并按比例混合不同来源的数据。</li>
<li><strong>词元切分</strong>：使用与 HuggingFace 兼容的 Tokenizer 对文档进行分词处理，生成可供训练使用的 tokens。</li>
</ol>
<h4 id="2-4-数据处理“菜谱”"><a href="#2-4-数据处理“菜谱”" class="headerlink" title="2.4 数据处理“菜谱”"></a><strong>2.4 数据处理“菜谱”</strong></h4><p>Dolma 工具包针对不同数据类型和数据来源提供了特定的数据处理“菜谱”：</p>
<ul>
<li><p><strong>网页（CC or C4）</strong>：</p>
<ul>
<li><strong>语种</strong>：先检测语言，确保是目标语种。</li>
<li><strong>去重</strong>：两次去重处理，包括段落去重和 URL 去重。</li>
<li><strong>质量过滤</strong>：过滤掉没有终止符的文本、Gopher 过滤规则、重复 token 超过 100 次的文档。</li>
<li><strong>内容过滤</strong>：检测并过滤掉毒性内容和 PII（Personal Identifiable Information）信息。</li>
</ul>
</li>
<li><p><strong>论坛（Reddit）</strong>：</p>
<ul>
<li><strong>语种检测</strong>：确保文本属于目标语言。</li>
<li><strong>质量过滤</strong>：过滤掉评论过短、点赞数少的内容。</li>
<li><strong>内容过滤</strong>：检测并去除包含被禁止、毒性、NSFW 内容的评论。</li>
</ul>
</li>
<li><p><strong>论文（Semantic Scholar）</strong>：</p>
<ul>
<li><strong>语种检测</strong>：确保内容是目标语言。</li>
<li><strong>质量过滤</strong>：过滤掉含有重复 token 超过 100 次的文档。</li>
</ul>
</li>
<li><p><strong>代码（The Stack）</strong>：</p>
<ul>
<li><strong>编程语种</strong>：根据需要筛选特定的编程语言。</li>
<li><strong>质量过滤</strong>：移除序言部分的版权声明，遵循 RedPajama v1 和 Starcoder 过滤规则。</li>
<li><strong>内容过滤</strong>：检测 PII 信息（如邮箱、电话、IP 地址），若文档中包含 6 个以上 PII 信息，移除整个语料。</li>
</ul>
</li>
<li><p><strong>维基（Wikipedia &amp; Wikibooks）</strong>：</p>
<ul>
<li>移除少于 25 个 utf-8 字符的网页。</li>
</ul>
</li>
<li><p><strong>书籍（Gutenberg）</strong>：</p>
<ul>
<li>对每段内容进行语言分类，如果整本书的平均语言得分低于 0.5，则移除。</li>
<li>移除少于 25 个 utf-8 字符的网页，并过滤掉重复 token 超过 100 次的内容。</li>
</ul>
</li>
</ul>
<h4 id="2-5-数据格式"><a href="#2-5-数据格式" class="headerlink" title="2.5 数据格式"></a><strong>2.5 数据格式</strong></h4><p>Dolma 对数据格式有严格要求，以确保数据在处理和训练中具有一致性：</p>
<ol>
<li><p><strong>id字段</strong>：该字段非常重要，用于追溯每个版本的每个文档到原始源文档，确保文档在不同版本中保持唯一性。id 在同一数据源内必须唯一。</p>
</li>
<li><p><strong>metadata字段</strong>：包含任何特定于源的信息，例如代码许可证、论文标识符（DOI、arXiv ID 等）。应尽可能保留源特定标识符，以确保数据的完整性和可追溯性。</p>
</li>
</ol>
<p>Dolma 的标准格式如下，数据清洗前应符合以下结构：<br><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;12345&quot;</span><span class="punctuation">,</span>           <span class="comment">// 必填：来源特定的唯一标识符，用于标记该文档</span></span><br><span class="line">    <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;示例文本内容&quot;</span><span class="punctuation">,</span>  <span class="comment">// 必填：文档的文本内容</span></span><br><span class="line">    <span class="attr">&quot;source&quot;</span><span class="punctuation">:</span> <span class="string">&quot;common-crawl&quot;</span><span class="punctuation">,</span> <span class="comment">// 必填：数据来源，例如 peS2o、common-crawl 等</span></span><br><span class="line">    <span class="attr">&quot;added&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2024-09-23T12:34:56Z&quot;</span><span class="punctuation">,</span> <span class="comment">// 可选：数据被 AI2 获取的时间戳</span></span><br><span class="line">    <span class="attr">&quot;created&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2024-01-01T08:00:00Z&quot;</span><span class="punctuation">,</span> <span class="comment">// 可选：原始文档创建的时间戳（如不可用，最好做出合理的推断）</span></span><br><span class="line">    <span class="attr">&quot;metadata&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span>            <span class="comment">// 可选：与数据源相关的特定元数据信息</span></span><br><span class="line">        <span class="attr">&quot;author&quot;</span><span class="punctuation">:</span> <span class="string">&quot;张三&quot;</span><span class="punctuation">,</span>    <span class="comment">// 示例：作者信息</span></span><br><span class="line">        <span class="attr">&quot;keywords&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;示例&quot;</span><span class="punctuation">,</span> <span class="string">&quot;文本&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span> <span class="comment">// 示例：关键词</span></span><br><span class="line">        <span class="attr">&quot;license&quot;</span><span class="punctuation">:</span> <span class="string">&quot;CC BY-SA&quot;</span> <span class="comment">// 示例：数据的许可信息</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></p>
<p>Dolma流程格式：<br><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;source&quot;</span><span class="punctuation">:</span> <span class="string">&quot;...&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;...&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;attributes&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;toxicity&quot;</span><span class="punctuation">:</span> <span class="number">0.7</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></p>
<h4 id="2-6-数据处理与过滤命令"><a href="#2-6-数据处理与过滤命令" class="headerlink" title="2.6 数据处理与过滤命令"></a><strong>2.6 数据处理与过滤命令</strong></h4><p>在实际数据清洗中，Dolma 提供了一系列的命令用于处理和过滤数据【40】：</p>
<ol>
<li><strong>dolma tag</strong>：使用标记器（taggers）对文档进行标记，例如标记语言、质量等属性。</li>
<li><strong>dolma dedupe</strong>：创建 Bloom 过滤器索引文件，对文本进行去重处理。</li>
<li><strong>dolma mix</strong>：根据标签筛选并按比例混合训练数据。</li>
<li><strong>dolma tokens</strong>：使用 Huggingface Tokenizer 对文档进行分词处理。</li>
</ol>
<h4 id="2-7-词元切分（Tokenization）"><a href="#2-7-词元切分（Tokenization）" class="headerlink" title="2.7 词元切分（Tokenization）"></a><strong>2.7 词元切分（Tokenization）</strong></h4><ul>
<li><strong>原料准备</strong>：训练语料一般为 JSONL 格式文件，使用 gz 等形式进行压缩。</li>
<li><strong>Tokenizer</strong>：可重用已有的 tokenizer，或者使用 BPE、SentencePiece 等重新训练一个新的 tokenizer。</li>
<li><strong>输出</strong>：以 npy 格式保存生成的 tokens。</li>
</ul>
<p><strong>词元切分的流程与问题解决</strong>：</p>
<ul>
<li><strong>中文支持</strong>：Dolma 默认的 Tokenizer 对中文支持较差，建议选择其他支持中文的 Tokenizer，如 Qwen2，或自行训练一个。</li>
<li><strong>数据格式问题</strong>：当使用新词表且词表数量超过 65536 时，可能会造成 id 溢出，需要手动修改 numpy 保存和训练的 dtype 为 uint32。存储空间会因此扩大一倍。</li>
<li><strong>特殊 Tokens</strong>：确保 Tokenizer 设置、Tokenize 过程和训练设置的 End of sentence (EOS) 等特殊 tokens 保持一致。</li>
<li><strong>建议</strong>：处理完成后，查看生成的内容，确保能够正常解码。</li>
</ul>
<h3 id="三、大模型预训练与OLMo框架"><a href="#三、大模型预训练与OLMo框架" class="headerlink" title="三、大模型预训练与OLMo框架"></a><strong>三、大模型预训练与OLMo框架</strong></h3><h4 id="3-1-OLMo简介"><a href="#3-1-OLMo简介" class="headerlink" title="3.1 OLMo简介"></a><strong>3.1 OLMo简介</strong></h4><ul>
<li><strong>OLMo</strong> 是由 AI2（Allen Institute for AI）开源的一个大型语言模型（LLM），全称为 <strong>Open Language Model</strong>。</li>
<li><strong>完全开源</strong>：OLMo 不仅开源了模型的权重，还开源了整个训练过程中的数据、训练代码和评估代码，方便用户了解和复现模型训练的全过程。</li>
<li><strong>集成性好</strong>：只需要具备 GPU 资源，任何用户都可以利用 OLMo 从零开始快速训练自己的 LLM，这极大地降低了大模型预训练的门槛，方便研究人员和开发者进行探索和实践。</li>
</ul>
<h4 id="3-2-OLMo安装"><a href="#3-2-OLMo安装" class="headerlink" title="3.2 OLMo安装"></a><strong>3.2 OLMo安装</strong></h4><p>首先根据您的操作系统的指示安装 <a target="_blank" rel="noopener" href="https://pytorch.org">PyTorch</a>。</p>
<p>如果希望从源代码进行安装，请运行以下命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/allenai/OLMo.git</span><br><span class="line"><span class="built_in">cd</span> OLMo</span><br><span class="line">pip install -e .[all]</span><br></pre></td></tr></table></figure>
<p>否则，您可以直接从 PyPI 安装模型代码，使用以下命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install ai2-olmo</span><br></pre></td></tr></table></figure>
<h4 id="3-3-OLMo预训练"><a href="#3-3-OLMo预训练" class="headerlink" title="3.3 OLMo预训练"></a><strong>3.3 OLMo预训练</strong></h4><p>用于训练官方 OLMo 模型的配置文件可以在 <a target="_blank" rel="noopener" href="https://github.com/allenai/OLMo/blob/main/configs/official"><code>configs/official/</code></a> 目录中找到。</p>
<p>在更新配置文件中的数据路径后，您可以使用 <code>torchrun</code> 启动训练。</p>
<p>例如，要在单个 8x GPU 节点上启动 1B 模型的训练，请运行：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torchrun --nproc_per_node=8 scripts/train.py configs/official/OLMo-1B.yaml</span><br></pre></td></tr></table></figure>
<p>要从检查点恢复训练，可以将路径（本地或 URL）传递给 <code>scripts/train.py</code>，并使用 <code>--load_path</code> 参数。</p>
<p>例如，要从 OLMo 1B 运行的第 1000 步恢复训练：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torchrun --nproc_per_node=8 scripts/train.py configs/official/OLMo-1B.yaml --load_path=https</span><br><span class="line"></span><br><span class="line">://olmo-checkpoints.org/ai2-llm/olmo-small/w1r5xfzt/step1000-unsharded</span><br></pre></td></tr></table></figure>
<h4 id="3-3-推理"><a href="#3-3-推理" class="headerlink" title="3.3 推理"></a><strong>3.3 推理</strong></h4><p>您可以使用 Hugging Face 来对 OLMo Transformers 检查点运行推理：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM, AutoTokenizer</span><br><span class="line"></span><br><span class="line">olmo = AutoModelForCausalLM.from_pretrained(<span class="string">&quot;allenai/OLMo-7B-0724-hf&quot;</span>)</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;allenai/OLMo-7B-0724-hf&quot;</span>)</span><br><span class="line"></span><br><span class="line">message = [<span class="string">&quot;Language modeling is &quot;</span>]</span><br><span class="line">inputs = tokenizer(message, return_tensors=<span class="string">&#x27;pt&#x27;</span>, return_token_type_ids=<span class="literal">False</span>)</span><br><span class="line">response = olmo.generate(**inputs, max_new_tokens=<span class="number">100</span>, do_sample=<span class="literal">True</span>, top_k=<span class="number">50</span>, top_p=<span class="number">0.95</span>)</span><br><span class="line"><span class="built_in">print</span>(tokenizer.batch_decode(response, skip_special_tokens=<span class="literal">True</span>)[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>或者，使用 Hugging Face 的 pipeline ：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line">olmo_pipe = pipeline(<span class="string">&quot;text-generation&quot;</span>, model=<span class="string">&quot;allenai/OLMo-7B-0724-hf&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(olmo_pipe(<span class="string">&quot;Language modeling is&quot;</span>))</span><br></pre></td></tr></table></figure>
<h3 id="四、指令微调与LLaMA-Factory框架"><a href="#四、指令微调与LLaMA-Factory框架" class="headerlink" title="四、指令微调与LLaMA-Factory框架"></a><strong>四、指令微调与LLaMA-Factory框架</strong></h3><h4 id="4-1-指令微调简介"><a href="#4-1-指令微调简介" class="headerlink" title="4.1 指令微调简介"></a><strong>4.1 指令微调简介</strong></h4><p><strong>指令微调（Instruction Tuning）</strong> 是对预训练后的大语言模型（LLM）进行参数微调的过程，也被称为<strong>有监督微调（Supervised Fine-tuning, SFT）</strong>。在指令微调的过程中，首先需要收集或构建包含指令信息的训练实例，然后通过有监督的方式对模型的参数进行微调。经过指令微调后的大语言模型具备较强的指令遵循能力，能够通过零样本学习（Zero-Shot Learning）的方式解决多种下游任务。</p>
<h4 id="4-2-训练流程"><a href="#4-2-训练流程" class="headerlink" title="4.2 训练流程"></a><strong>4.2 训练流程</strong></h4><ol>
<li><strong>选择基座模型</strong>：选择已预训练的基座模型，或者使用自己预训练的模型。</li>
<li><strong>构建高质量数据集</strong>：根据微调策略构建高质量的指令数据，注意数据质量与多样性，以及不同领域数据的比例。</li>
<li><strong>训练模型</strong>：根据硬件资源和训练目标，配置训练超参数、数据配置等。</li>
<li><strong>监控与评估</strong>：通过 LLaMA Board 等工具实时监控训练过程，观察 loss 曲线，调整训练策略。</li>
<li><strong>评测与推理</strong>：对微调后的模型进行评测，验证其在特定任务上的性能。<h4 id="4-3-指令数据的构建"><a href="#4-3-指令数据的构建" class="headerlink" title="4.3 指令数据的构建"></a><strong>4.3 指令数据的构建</strong></h4></li>
</ol>
<p><strong>指令数据的组成</strong>：</p>
<ul>
<li><strong>任务描述（指令）</strong>：描述模型需要完成的任务，例如回答问题、生成代码等。</li>
<li><strong>任务输入</strong>：提供给模型的任务输入数据，模型需要根据输入生成对应的输出。</li>
<li><strong>任务输出</strong>：预期的任务结果或答案。</li>
<li><strong>历史记录</strong>：在多轮对话中，历史记录用来保持上下文信息，帮助模型理解对话的连续性。</li>
</ul>
<p>在实际应用中，指令微调数据集可以包含<strong>单轮对话</strong>（无历史记录）和<strong>多轮对话</strong>（包含历史记录）。</p>
<p><strong>指令数据集示例</strong>：</p>
<ul>
<li><strong>OpenHermes</strong>、<strong>Alpaca</strong>、<strong>Codeforces-Python-Submissions-SFT</strong> 等数据集，涵盖了通用领域、代码生成、数学推理等不同类型的数据。推荐的数据集比例为通用数据与领域数据保持平衡，例如 5:1。</li>
</ul>
<h4 id="4-4-选择-SFT-训练框架：LLaMA-Factory"><a href="#4-4-选择-SFT-训练框架：LLaMA-Factory" class="headerlink" title="4.4 选择 SFT 训练框架：LLaMA-Factory"></a><strong>4.4 选择 SFT 训练框架：LLaMA-Factory</strong></h4><p><strong>LLaMA-Factory</strong> 是一个统一、高效的微调框架，集成了多种高效训练方法，支持对 100 多种大型语言模型（LLMs）的灵活微调。该框架的特点和优势包括：</p>
<ul>
<li><strong>易于使用</strong>：通过内置的 Web 用户界面 LlamaBoard，无需编码即可灵活地定制模型微调过程。</li>
<li><strong>多模型支持</strong>：支持多种模型，包括 LLaMA、LLaVA、Mistral 等，且提供多种训练方法，如继续预训练、多模态监督微调、奖励建模、PPO、DPO、KTO、ORPO 等。</li>
<li><strong>高效性</strong>：支持全参数微调（Full Fine Tuning, FFT）、参数高效微调（PEFT），以及多种量化技术和参数效率算法，如 LoRA（Low-Rank Adaptation）、Q-LoRA、FlashAttention-2 等，减少 GPU 内存使用并提高训练速度。</li>
<li><strong>实验监控</strong>：集成了 LlamaBoard、TensorBoard、Wandb、MLflow 等工具，方便跟踪训练进度和性能。</li>
</ul>
<h4 id="4-5-微调过程与配置"><a href="#4-5-微调过程与配置" class="headerlink" title="4.5 微调过程与配置"></a><strong>4.5 微调过程与配置</strong></h4><p><strong>数据集注册</strong>：</p>
<ul>
<li>将数据集放在 <code>data</code> 文件夹下，并在 <code>data_info.json</code> 中注册数据集的信息，包括数据集名称、地址和格式。</li>
</ul>
<p><strong>训练配置示例</strong>：</p>
<ul>
<li>以下是对模型进行微调的配置文件示例：<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># model</span></span><br><span class="line"><span class="attr">model_name_or_path:</span> <span class="string">meta-llama/Meta-Llama-3-8B-Instruct</span></span><br><span class="line"><span class="comment"># method</span></span><br><span class="line"><span class="attr">stage:</span> <span class="string">sft</span></span><br><span class="line"><span class="attr">do_train:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">finetuning_type:</span> <span class="string">full</span></span><br><span class="line"><span class="comment"># ddp</span></span><br><span class="line"><span class="attr">ddp_timeout:</span> <span class="number">180000000</span></span><br><span class="line"><span class="attr">deepspeed:</span> <span class="string">examples/deepspeed/ds_z3_config.json</span></span><br><span class="line"><span class="comment"># dataset</span></span><br><span class="line"><span class="attr">dataset:</span> <span class="string">identity,alpaca_gpt4_en</span></span><br><span class="line"><span class="attr">template:</span> <span class="string">llama3</span></span><br><span class="line"><span class="attr">cutoff_len:</span> <span class="number">1024</span></span><br><span class="line"><span class="attr">max_samples:</span> <span class="number">1000</span></span><br><span class="line"><span class="attr">val_size:</span> <span class="number">0.1</span></span><br><span class="line"><span class="attr">overwrite_cache:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">preprocessing_num_workers:</span> <span class="number">16</span></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line"><span class="attr">output_dir:</span> <span class="string">saves/llama3-8b/full/sft</span></span><br><span class="line"><span class="attr">logging_steps:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">save_steps:</span> <span class="number">500</span></span><br><span class="line"><span class="attr">plot_loss:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">overwrite_output_dir:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></li>
<li>其中包含了模型名称、训练方法、数据集名称、数据预处理进程数、输出路径等信息。该配置文件可以灵活调整，以适应不同的训练需求。</li>
</ul>
<p><strong>训练与评估设置</strong>：</p>
<ul>
<li>单卡 batch size、梯度累积步数、学习率、训练 epoch、精度（如 FP16、BF16）等参数均可根据硬件资源进行调整。</li>
</ul>
<h4 id="4-6-训练策略"><a href="#4-6-训练策略" class="headerlink" title="4.6 训练策略"></a><strong>4.6 训练策略</strong></h4><p><strong>全量微调（Full Fine Tuning, FFT）</strong>：</p>
<ul>
<li>对全量参数进行训练，具有更高的训练成本，但能获得更全面的模型能力。然而，FFT 可能导致“灾难性遗忘”（Catastrophic Forgetting）现象，即在特定领域数据上微调后，模型在其他领域的表现可能下降。</li>
</ul>
<p><strong>参数高效微调（Parameter-Efficient Fine Tuning, PEFT）</strong>：</p>
<ul>
<li>仅对部分参数进行训练，常用的技术是 LoRA（Low-Rank Adaptation），通过添加旁路线性层 A 和 B，模型只需训练降维和升维的矩阵，实现高效微调。PEFT 能够以较低的训练成本提高模型在特定任务上的性能。</li>
</ul>
<h4 id="4-7-微调实例与训练过程"><a href="#4-7-微调实例与训练过程" class="headerlink" title="4.7 微调实例与训练过程"></a><strong>4.7 微调实例与训练过程</strong></h4><p><strong>训练实例</strong>：</p>
<ul>
<li>通过以下命令对 Llama3-8B-Instruct 模型进行微调、推理和合并操作：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">llamafactory-cli train examples/train_lora/llama3_lora_sft.yaml</span><br><span class="line">llamafactory-cli chat examples/inference/llama3_lora_sft.yaml</span><br><span class="line">llamafactory-cli <span class="built_in">export</span> examples/merge_lora/llama3_lora_sft.yaml</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>可视化训练过程</strong>：</p>
<ul>
<li>使用 LLaMA Board（由 Gradio 驱动）实现训练过程的可视化，方便监控训练的实时状态：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">llamafactory-cli webui</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="五、模型评测与OpenCompass"><a href="#五、模型评测与OpenCompass" class="headerlink" title="五、模型评测与OpenCompass"></a><strong>五、模型评测与OpenCompass</strong></h3><h4 id="5-1-OpenCompass简介"><a href="#5-1-OpenCompass简介" class="headerlink" title="5.1 OpenCompass简介"></a><strong>5.1 OpenCompass简介</strong></h4><p><strong>OpenCompass（司南）</strong> 是由上海人工智能实验室发布的一个开源大模型评测体系，旨在为大模型提供一个公平、开放和可复制的评估基准，已经成为目前权威的大型模型评估平台。OpenCompass 支持丰富的模型和数据集，提供分布式高效评测，具备多样化的评估范式、模块化设计和较强的可扩展性，同时具备实验管理和报告生成机制。</p>
<ul>
<li><strong>官方链接</strong>：<ul>
<li>GitHub 项目地址: <a target="_blank" rel="noopener" href="https://github.com/open-compass/opencompass">https://github.com/open-compass/opencompass</a></li>
<li>排行榜网站: <a target="_blank" rel="noopener" href="https://rank.opencompass.org.cn/home">https://rank.opencompass.org.cn/home</a></li>
</ul>
</li>
</ul>
<h4 id="5-2-OpenCompass安装"><a href="#5-2-OpenCompass安装" class="headerlink" title="5.2 OpenCompass安装"></a><strong>5.2 OpenCompass安装</strong></h4><p>安装 OpenCompass 的步骤如下：</p>
<ol>
<li><strong>创建 Conda 虚拟环境</strong>：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda create --name opencompass python=3.10 pytorch torchvision pytorch-cuda -c nvidia -c pytorch -y</span><br><span class="line">conda activate opencompass</span><br></pre></td></tr></table></figure></li>
<li><strong>克隆 OpenCompass 项目源码</strong>：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/open-compass/opencompass opencompass</span><br><span class="line"><span class="built_in">cd</span> opencompass</span><br></pre></td></tr></table></figure></li>
<li><strong>安装依赖</strong>：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install -r ./requirements/runtime.txt</span><br><span class="line">pip install -e .</span><br></pre></td></tr></table></figure></li>
<li><strong>下载测评数据</strong>：使用以下命令下载官方测评数据，并解压到 <code>opencompass</code> 目录下的 <code>data</code> 目录：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/open-compass/opencompass/releases/download/0.1.8.rc1/OpenCompassData-core-20231110.zip</span><br><span class="line">unzip OpenCompassData-core-20231110.zip</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="5-3-OpenCompass整体流程"><a href="#5-3-OpenCompass整体流程" class="headerlink" title="5.3 OpenCompass整体流程"></a><strong>5.3 OpenCompass整体流程</strong></h4><p>在 OpenCompass 中评估一个模型通常包括以下几个阶段：</p>
<ul>
<li><strong>配置</strong>：配置评估过程，包括选择模型、数据集、评估策略、计算后端等，还可以定义结果的显示方式。</li>
<li><strong>推理与评估</strong>：推理阶段让模型从数据集产生输出，评估阶段则衡量这些输出与标准答案的匹配程度。这两个过程会被拆分为多个同时运行的“任务”以提高效率。</li>
<li><strong>可视化</strong>：评估完成后，OpenCompass 会将结果整理成易读的表格，并保存为 CSV 和 TXT 文件，还可以在飞书客户端中及时获得评测状态报告。</li>
</ul>
<h4 id="5-4-OpenCompass配置文件"><a href="#5-4-OpenCompass配置文件" class="headerlink" title="5.4 OpenCompass配置文件"></a><strong>5.4 OpenCompass配置文件</strong></h4><ul>
<li><strong>配置文件命名</strong>：一般命名为 <code>eval_xxx.py</code>。</li>
<li><strong>主要配置项</strong>：<ul>
<li><strong>datasets</strong>：指定使用的数据集列表。</li>
<li><strong>models</strong>：指定使用的模型、分词器和推理方法（如 ppl、gen）。</li>
<li><strong>infer</strong>：指定测评任务的分割方式（如 <code>SizePartitioner</code>、<code>NaivePartitioner</code>）。</li>
<li><strong>meta_template</strong>：需要与 SFT 阶段使用的模板保持一致。</li>
</ul>
</li>
</ul>
<p>如使用 vllm 版本，可使用 <code>gpu_memory_utilization</code> 等额外参数，若发生显存不足则可调整相关参数。</p>
<h4 id="5-5-OpenCompass模型准备"><a href="#5-5-OpenCompass模型准备" class="headerlink" title="5.5 OpenCompass模型准备"></a><strong>5.5 OpenCompass模型准备</strong></h4><p>在进行模型评测之前，首先需要将模型转化为适合评测的格式：</p>
<ul>
<li><strong>分布式训练结果转换</strong>：将分布式训练的结果转换为 unsharded 形式：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python OLMo/scripts/unshard.py &lt;sharded_checkpoint_dir&gt; &lt;unsharded_checkpoint_dir&gt;</span><br></pre></td></tr></table></figure></li>
<li><strong>将检查点转换为 HuggingFace 格式</strong>：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python /OLMo/scripts/convert_olmo_to_hf_new.py --input_dir=&lt;unsharded_checkpoint_dir&gt; --output_dir=&lt;hf_checkpoint_dir&gt;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>如果使用 <code>llama-factory</code> 或 <code>trl</code> 等包进行模型训练/微调，则无需转换。使用 OLMo 训练的模型在进行 SFT 或评测前均需完成 unsharded 格式转换与 HuggingFace 格式转换。</p>
<h4 id="5-6-OpenCompass运行与输出"><a href="#5-6-OpenCompass运行与输出" class="headerlink" title="5.6 OpenCompass运行与输出"></a><strong>5.6 OpenCompass运行与输出</strong></h4><p>在 <code>opencompass</code> 目录下，运行以下命令启动评测：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">nohup</span> python run.py ./configs/eval_olmo.py &gt; nohup.out &amp;</span><br></pre></td></tr></table></figure></p>
<ul>
<li>运行过程中，会在 <code>&lt;workdir&gt;</code> 目录下生成一个以时间戳命名的文件夹，其中包含 <code>configs</code>、<code>logs</code>、<code>predictions</code>、<code>results</code>、<code>summary</code> 等文件夹。</li>
<li>如果在评测过程中遇到出错的项目，OpenCompass 会自动跳过；若错误过多，可查看对应的 <code>log</code> 文件进行排查。</li>
<li>评测完成后，可以在 <code>summary</code> 文件夹中找到每个测评数据集的得分（以 TXT 和 CSV 两种形式记录）。</li>
</ul>
<p><strong>停止进程</strong>：如需终止评测进程，可执行以下命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -elf | grep opencompass | awk <span class="string">&#x27;&#123;print $4&#125;&#x27;</span> | xargs <span class="built_in">kill</span></span><br></pre></td></tr></table></figure></p>
<h4 id="5-7-OpenCompass评测数据集"><a href="#5-7-OpenCompass评测数据集" class="headerlink" title="5.7 OpenCompass评测数据集"></a><strong>5.7 OpenCompass评测数据集</strong></h4><ul>
<li><strong>MMLU（Multilingual Massively Multilingual Understanding）</strong>：多选问答任务的英文评测数据集，涵盖 STEM、人文、社会科学等领域的 57 个学科，共 15908 个问题，评估模型的多任务处理能力。</li>
<li><strong>CMMLU</strong>：综合性的中文评估基准，专门用于评估模型在中文语境下的知识和推理能力，涵盖 67 个主题，共 11528 个问题，包含少样本和测试集部分。</li>
<li><strong>C-Eval</strong>：中文 LLM 评估基准，包含 13948 个多项选择问题，涉及 52 个学科，分为初中、高中、大学和专业四个难度级别，并设有 C-Eval Hard 子集用于高级推理能力的评估。</li>
<li><strong>GSM8K</strong>：中小学数学应用题的英文数据集，包含 8.5K 高质量数学问题，考察模型在多步骤数学推理任务中的性能。</li>
<li><strong>MATH</strong>：数学竞赛问题数据集，包含 12500 道题目，提供了完整的分步骤解答方案，评估模型在数学推理和解题方面的能力。</li>
<li><strong>MBPP（Mostly Basic Python Problems）</strong>：由约 1401 个 Python 编程问题组成，旨在评估模型的编程基础和标准库功能。</li>
<li><strong>HumanEval</strong>：由 OpenAI 发布的编程问题数据集，包含 164 个编程任务，评估模型在代码生成和编写方面的能力。</li>
<li><strong>BBH（Big Bench Hard）</strong>：评估模型在高难度推理任务方面的性能，共 23 个具有挑战性的 BIG-Bench 任务，每类约 250 个测试案例。</li>
<li><strong>GAOKAO-BENCH</strong>：利用中国高考试题作为数据集，评估模型的语言理解和逻辑推理能力。</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/12/05/Olmo%E5%8F%8Adolma%E5%AE%9E%E8%B7%B5/" data-id="cm4boxx5h0005ykfybv0hb0uz" data-title="Olmo及dolma实践" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2024/12/06/MoE-Rag-Peft-RLHF-DPO/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          MoE_Rag_Peft_RLHF_DPO
        
      </div>
    </a>
  
  
    <a href="/2024/12/05/DeepSpeed%E7%9B%B8%E5%85%B3/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">DeepSpeed相关</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/12/">December 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/11/">November 2024</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/12/06/MoE-Rag-Peft-RLHF-DPO/">MoE_Rag_Peft_RLHF_DPO</a>
          </li>
        
          <li>
            <a href="/2024/12/05/Olmo%E5%8F%8Adolma%E5%AE%9E%E8%B7%B5/">Olmo及dolma实践</a>
          </li>
        
          <li>
            <a href="/2024/12/05/DeepSpeed%E7%9B%B8%E5%85%B3/">DeepSpeed相关</a>
          </li>
        
          <li>
            <a href="/2024/12/05/DP%E5%92%8CDDP/">DP和DDP</a>
          </li>
        
          <li>
            <a href="/2024/12/05/%E5%8D%83%E9%97%AE%E7%9B%B8%E5%85%B3/">千问相关</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>